# cs(OS)



#### 멀티 프로세스

> 하나의 컴퓨터에 여러 CPU장착 -> 하나 이상의 프로세스를 동시에 처리

장점 : 안전성

단점 : 각각 독립된 메모리 영역을 가지고 있어, 작업량이 많을수록 오버헤드가 발생한다.



#### 멀티 스레드

> 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌

장점 : 여러 스레드가 메모리를 공유하기 때문에, 시간, 자원손실이 감소한다.



#### 프로세스와 주소 공간

> 프로그램이 CPU에 의해 실행됨 -> 프로세스가 생성되고 메모리에 프로세스 주소 공간이 할당됨

프로세스 주소 공간에는 코드, 데이터, 스택으로 이루어져 있다.

- 코드 : 프로그램 소스 코드
- 데이터 : 전역 변수
- 스택 : 지역 변수, 임시 변수



#### PCB와 Context Switching

Process Management

> CPU가 프로세스가 여러개일 때, CPU스케줄링을 통해 관리하는 것

프로세스들의 특징을 가지고 있는 것이 바로 `Process Metadata`. 

- Process metadata
  - Process ID
  - Process State
  - Process Priority
  - CPU Registers
  - Owner
  - CPU Usage
  - Memeory Usage

이 메타데이터는 프로세스가 생성되면 PCB(process control block)라는 곳에 저장됨



##### PCB

> 프로세스 메타데이터를 저장해놓는 곳. 한 PCB안에는 한 프로세스의 정보가 담김

![img](https://t1.daumcdn.net/cfile/tistory/25673A5058F211C224)

```
프로그램 실행 => 프로세스 생성 => 프로세스 주소 공간에 코드, 데이터, 스택 생성 => 이 프로세스의 메타데이터들이 PCB에 저장.
```



##### PCB가 왜 필요해?

CPU에서는 프로세스의 상태에 따라 교체 작업이 이루어진다. 이때, 앞으로 다시 수행할 대기 중인 프로세스에 관한 저장값을 PCB에 저장해 두는 것이다.

##### PCB는 어떻게 관리되는거야?

Linked list방식으로 관리된다.

PCB List Head에 PCB들이 생성될 때마다 붙게 된다. 주소 값으로 연결이 이루어져있는 연결 리스트이기 때문에 삽입, 삭제가 용이하다.

즉, 프로세스가 생성되면 해당 PCB가 생성되고 프로세스 완료시 제거된다.



이렇게 수행 중인 프로세스를 변경할 때, CPU의 정보가 변경되는 것을 `Context Switching`이라 한다.



#### Context Switching

> CPU가 이전의 프로세스 상태를 PCB에 보관하고, 또 다른 프로세스의 정보를 PCB에 읽어 레지스터에 적재하는 과정

보통 인터럽트가 발생하거나, 실행 중인 CPU사용 허가시간을 모두 소모하거나, 입출력을 위해 대기해야 하는 경우 Context Switching이 발생한다.

`즉, 프로세스가 Ready-> Running, Running -> Ready, Running -> Waiting처럼 상태 변경 시 발생`

##### Context Switching의 Overhead란?

overhead는 과부하라는 뜻으로 보통 안좋은 말로 쓰인다.

하지만 프로세스 작업 중에는 Overhead를 감수해야 하는 상황이 있다.

```
프로세스를 수행하다가 입출력 이벤트가 발생하여 대기 상태로 전환시킴
이때, CPU를 그냥 놀게 놔두는 것보다 다른 프로세스를 수행시키는 것이 효율적
```

즉, CPU에 계속 프로세스를 수행시키도록 하기 위해서 다른 프로세스를 실행시키고, Context Switching하는 것.

CPU가 놀지 않도록 만들고, 사용자에게 빠르게 일처리를 제공해주기 위한 것이다.



#### IPC(Inter Process Communication)

독립적 구조를 가진 프로세스 간의 통신을 해야하는 상황에 IPC통신을 사용한다.

##### IPC 종류

1. 익명 PIPE

   파이프는 두 개의 프로세스를 연결하는데 하나의 프로세스는 데이터를 쓰기만, 하나는 읽기만 할 수 있다.

   한쪽 방향으로 통신이 가능한 반이중 통신이라고 부른다.

   따라서 양쪽 모두 송수신을 하려면 2개의 파이프를 만들어야 한다.

   매우 간단하게 사용할 수 있는 장점이 있고, 단순한 흐름을 가질 땐 파이프를 사용하는 것이 효율적이다.

2. Named PIPE(FIFO)

   익명 파이프는 통신할 프로세스를 명확히 알 수 있는 경우에만 사용한다.

   Named 파이프는 전혀 모르는 상태의 프로세스들 사이 통신에 사용한다.

3. Message Queue

   입출력 방식은 Named 파이프와 동일함.

4. 공유 메모리

   데이터 자체를 공유하도록 지원하는 방법.

   프로세스의 메모리 영역은 독립적으로 가지며 다른 프로세스가 접근하지 못하도록 보호되어야 한다. 하지만 다른 프로세스가 데이터를 사용하도록 해야하는 상황도 필요할 것이다. 파이프를 이용해 통신을 통해 데이터 전달도 가능하지만, 스레드처럼 메모리를 공유하도록 해준다면 더욱 편할 것이다.

   공유 메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용해준다.

   프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간을 할당해주고 이후 모든 프로세스는 해당 메모리 영역에 접근할 수 있게 된다.

5. 메모리 맵

   공유 매개체를 파일+메모리로 메모리에 매핑해서 공유시킨다.



#### CPU 스케줄링

##### 스케줄링

> CPU를 잘 사용하기 위해 프로세스를 잘 배정하기

- 조건 : 오버헤드 낮게 사용률 높게 기아 현상 낮게
- 목표
  1. batch system : 가능하면 많은 일 수행. 시간보단 처리량 중요
  2. interactive system : 빠른 응답시간, 적은 대기시간.
  3. realtime system : 기한 맞추기.

##### 선점 / 비선점 스케줄링

- 선점(preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우.
- 비선점(nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 떄까지 실행 보장 (처리 시간 예측 어려움)

##### 프로세스 상태

![download (5)](https://user-images.githubusercontent.com/13609011/91695344-f2dfae80-eba8-11ea-9a9b-702192316170.jpeg)

- 비선점 스케줄링 : Interrupt, Scheduler Dispatch
- 선점 스케줄링 : I/O or Event Wait

---

##### 프로세스의 상태 전이

승인(Admitted) : 프로세스 생성이 가능하여 승인됨.

스케줄러 디스패치(scheduler dispatch) : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것.

인터럽트(Interrupt) : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것.

입출력 또는 이벤트 대기(I/O or Event wait) : 실행중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것.

입출력 또는 이벤트 완료(I/O or Event completion) : 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것.



#### CPU 스케줄링의 종류

- 비선점 스케줄링
  1. FCFS(First Come First Served)
     - 큐에 도착한 순서대로 CPU 할당
     - 실행 시간이 짧은게 뒤로 가면 평균 대기 시간이 길어짐
  2. SJF(Shortest Job First)
     - 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
     - FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리
  3. HRN(Highest Response-ratio Next)
     - 우선 순위를 계산하여 점유 불평등을 보완한 방법(SJF의 단점 보완)
     - 우선순위 = (대기 시간 + 실행 시간) / (실행 시간)



- 선점 스케줄링
  1. Priority Scheduling
     - 우선순위를 부여하여 우선순위가 높은 순서대로 처리
     - 우선 순위가 낮은 프로세스가 무한정 기다리는 starvation이 생길 수 있음
  2. Round Robin
     - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 Time Quantum만큼 CPU를 할당받음.
     - Time Quantum or Time Slice : 실행의 최소 단위 시간
     - 할당 시간이 크면 FCFS와 같아지고, 작으면 Context Switching이 잦아져서 오버헤드 증가.



## 데드락(Deadlock)

> 프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태
>
> '교착 상태' 라고도 부름
>
> 시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생

데드락이 일어나는 경우

![img](https://t1.daumcdn.net/cfile/tistory/243E89355714C26E28)

프로세스1과 2가 자원1, 2를 모두 얻어야 한다고 가정해보자

- t1 : 프로세스 1이 자원 1을 얻음 / 프로세스 2가 자원 2를 얻음
- t2 : 프로세스 1이 자원 2를 기다림 / 프로세스 2가 자원 1을 기다림

서로 원하는 자원이 상대방에 할당되어 있어서 두 프로세스는 무한정 wait상태에 빠짐 -> Deadlock

**[주로 발생하는 경우]**

- 멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생
- 한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 이때 프로세스는 대기 상태로 들어감
- 대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때 '교착 상태'발생



#### Deadlock 발생 조건

4가지 모두 성립해야 데드락 발생

1. 상호 배제(Mutual exclusion)

   자원은 한번에 한 프로세스만 사용할 수 있음

2. 점유 대기(Hold and wait)

   최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함.

3. 비선점(No preemption)

   다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음

4. 순환 대기(Circular wait)

   프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함



#### 데드락 처리

##### 교착 상태를 예방 / 회피

1. 예방(prevention)

   교착 상태 발생 조건 중 하나를 제거하면서 해결한다.

2. 회피(avoidance)

   교착 상태 발생 시 피해나가는 방법

   은행원 알고리즘(Banker's algorithm)

   - 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는 데서 유래함
   - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지를 사전에 검사하여 회피
   - 안정 상태면 자원 할당, 그렇지 않으면 다른 프로세스들이 자원 해지까지 대기

##### 교착 상태를 탐지 / 회복

교착 상태가 되도록 허용한 다음 회복시키는 방법



## 경쟁 상태(Race Condition)

공유 자원에 대해 여러 프로세스가 동시에 접근할 때, 결과값에 영향을 줄 수 있는 상태

> 동시 접근 시 자료의 일관성을 해치는 결과가 나타남

#### Race Condition이 발생하는 경우

1. 커널 작업을 수행하는 중에 인터럽트 발생



## 세마포와 뮤텍스

공유된 자원에 여러 프로세스가 동시에 접근하면서 문제가 발생할 수 있다. 이때 공유된 자원의 데이터는 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 둬야 한다.

이를 위해 나온 것이 `세마포어`.

세마포어 : 멀티프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법



##### 임계 구역(Critical Section)

여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분

공유 데이터를 여러 프로세스가 동시게 접근할 때 잘못된 결과를 만들 수 있기 때문에, 한 프로세스가 임계 구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야 한다.

구현 방법

```pseudocode
P(s);
// --- 임계구역
V(s);
```

```pseudocode
procedure P(s)
	while s=0 do wait
	s := s-1
end P

-- 임계 구역 --

procedure V(s)
	s := s + 1
end V
```

이를 통해 한 프로세스가 P 혹은 V를 수행하고 있는 동안 프로세스가 인터럽트 당하지 않게 된다. 이를 통해 상호배제 구현이 가능하게 되었다.

예시

> 최초 s값은 1, 수행할 프로세스가 A,B라고 가정하자

1. 먼저 도착한 A는 P(s)를 실행하여 s를 0으로 만들고 임계구역에 들어감
2. 그 뒤 도착한 B가 P(s)를 실행했지만 s가 0이기 때문에 대기
3. A가 임계구역을 마치고 V(s)를 실행하여 s를 다시 1로 만듬
4. B는 P(s)에서 수행할수 있게되었고, 임계구역으로 들어가 수행함



## 메모리 관리 전략

#### 메모리 관리 배경

각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.

Swapping : 메모리의 관리를 위해 사용되는 기법. 표준 Swapping 방식으로는 round-robin 과 같은 스케줄링의 다중 프로그래밍 환경에서 CPU할당이 끝난 프로세스의 메모리를 보조 기억장치로 내보내고 다른 프로세스의 메모리를 불러들일 수 있다.

> 이 과정을 swap(스왑시킨다) 라고 한다. 주 기억장치(RAM)으로 불러오는 과정을 swap-in, 보조기억장치로 내보내는 과정을 swap-out이라 한다. swap에는 큰 디스크 전송 시간이 필요하기 때문에 현재는 메모리 공간이 부족할때 swapping이 시작된다.

단편화(Fragmentation) : 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 자유공간들이 늘어나게 되는데, 이것이 단편화이다.

| `Process A` | free | `Process B` | free | `Process C` | free | `Process D` |
| ----------- | ---- | ----------- | ---- | ----------- | ---- | ----------- |

- 외부 단편화 : 물리 메모리 사이사이에 남는 공간이 분산되어 있을 때
- 내부 단편화 : 프로세스가 사용하는 메모리 공간에 남는 부분.

압축 : 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유 공간을 확보하는 방법이지만, 작업 효율이 좋지 않다.



#### Paging(페이징)

하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법. 외부 단편화와 압축 작업을 해소하기 위해 생긴 방법론으로, 물리 메모리는 frame이라는 고정 크기로 분리되어 있고, 논리 메모리는 페이지라 불리는 고정 크기의 블록으로 분리된다.(페이지 교체 알고리즘에 들어가는 페이지)

페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 장점이 있다.

- 단점 : 내부 단편화 문제의 비중이 늘어난다. 페이지의 크기가 1000B이고 프로세스가 3001의 메모리를 요구한다면 4개의 페이지를 사용하면서 999B의 메모리가 낭비되기 때문.

#### Segmentation(세그멘테이션)

페이징에서처럼 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트(segment)로 분할. 

- 단점 : segment 크기가 클 경우 할당하기가 어려움, 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 외부 단편화가 일어날 수 있음.

---



## 가상 메모리

다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 메모리에 올려두어야 한다. 가상 메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이며, 프로그램이 물리 메모리보다 커도 된다는 장점이 있다.

#### 가상 메모리 개발 배경

실행되는 코드의 전부를 물리 메모리에 존재시켜야 했고, 메모리 용량보다 큰 프로그램은 실행시킬 수 없었다. 또한, 여러 프로그램을 동시에 올리기엔 용량의 한계와 페이지 교체등의 성능 이슈가 발생한다. 또한, 가끔만 사용되는 코드가 차지하는 메모리를 확인할 수 있다는 점에서, 불필요하게 전체의 프로그램이 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있다.